{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "import math\n",
    "\n",
    "import os\n",
    "if os.getcwd()[-14:] != 'AIMS-immunopep':\n",
    "    default_path = os.getcwd()[:-10]\n",
    "    os.chdir(default_path)\n",
    "import aims_loader as aimsLoad\n",
    "import aims_analysis as aims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A theoretical consideration of immune communication channels\n",
    "So in this notebook, I'm going to try to actually use it as... a book, for notes.\n",
    "I want to go ahead and try to reason through some theoretical maxima of our possible communication channels.\n",
    "I think that there will be many assumptions here, not all of them correct, but open to argument here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick little refresher for the equations we're using here:\n",
    "\n",
    "Mutual Information formulation I'm using (standard definition):\n",
    "\\begin{equation} \\label{eq:1}\n",
    "I(X;Y)=H(X)-H(X|Y)\n",
    "\\end{equation}\n",
    "\n",
    "Conditional Entropy Equation in the more common formulation:\n",
    "\\begin{equation} \\label{eq:2}\n",
    "H(X|Y) = -\\sum_{x\\in X,y \\in Y}p(x,y)\\log_2\\dfrac{p(x,y)}{p(y)}\n",
    "\\end{equation}\n",
    "\n",
    "Conditional Entropy Equation I use in this work:\n",
    "\\begin{equation} \\label{eq:3}\n",
    "H(X|Y)=-\\sum_{Y}p(y)\\sum_{X}p(x|y)\\log_2p(x|y)\n",
    "\\end{equation}\n",
    "\n",
    "In both cases, our \"given\" is the amino acid at some position. So when talking about probabilities p(y), we want to talk about the probability of finding a given amino acid at that location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So let's start from the easier side of things, the peptides...\n",
    "Remember some of our fun facts from reading a couple of useful peptide papers:\n",
    "1. $\\color{red}{\\text{The whole peptidome contains ~10,000 proteins with mean length 449 Amino Acids}}$\n",
    "2. $\\color{red}{\\text{Each cell contains roughly 100,000 MHC molecules per cell, presenting ~10,000 peptides}}$\n",
    "3. $\\color{red}{\\text{In HeLa cells, the 40 most abundant proteins comprised 25\\% of the digested proteome}}$\n",
    "4. $\\color{red}{\\text{In these same cells, the 600 most abundant proteins comprised 75\\% of the proteome mass}}$\n",
    "5. $\\color{red}{\\text{By these estimates, peptides presented by the MHC represent at most 2\\% of all possible peptides in a cell}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutations of peptide possibilities\n",
    "n permute k, n options k location options WITH REPLACEMENT:\n",
    "\\begin{equation} \\label{eq:4}\n",
    "_nP_k = n^r\n",
    "\\end{equation}\n",
    "\n",
    "n permute k, n options k location options WITHOUT REPLACEMENT:\n",
    "\\begin{equation} \\label{eq:5}\n",
    "_nP_k = \\dfrac{n!}{(n-k)!}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, assume the max possible information encoded in peptides\n",
    "So the max possible would be to assume all peptides are 12 amino acids,\n",
    "and that each amino acid occurs at each location with equal probability. I do want to check that entropy is additive. So make sure that this is so..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Many Possible Peptides Can be Made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Peptides = 4.10e+15\n"
     ]
    }
   ],
   "source": [
    "# First, find the number of possibilities:\n",
    "# Without replacement (OF COURSE there is \"replacement\" in peptide sequences)\n",
    "#num_possibilities = math.factorial(20)/math.factorial(20-12)\n",
    "num_possibilities = 20**12\n",
    "sci_notation = \"{:.2e}\".format(num_possibilities)\n",
    "print('Possible Peptides = '+sci_notation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Peptide Shannon Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.86313713864835\n"
     ]
    }
   ],
   "source": [
    "# So that's a whole heap of possibilities.\n",
    "# Calculate the Shannon Entropy of these whole-peptide \"words\"\n",
    "# Assume each \"word\" has equal probability\n",
    "# We can then replace our \"sum\" with a multiplication by the number of \"words\"\n",
    "shannon_word=-num_possibilities*(1/num_possibilities)*math.log((1/num_possibilities),2)\n",
    "print(shannon_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Shannon Entropy By Amino Acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Entry Entropy = 4.321928094887363\n",
      "Shannon Word Entropy by AA = 51.863137138648355\n"
     ]
    }
   ],
   "source": [
    "shannon_single_entry = -20*(1/20)*math.log(1/20,2)\n",
    "print('Single Entry Entropy = '+str(shannon_single_entry))\n",
    "shannon_word_byAA = 12 * shannon_single_entry\n",
    "print('Shannon Word Entropy by AA = '+str(shannon_word_byAA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And, as we should expect, Entropy is Additive\n",
    "While this is very well known, it's always nice to repeat things as a sanity check. This is REALLY important, because now we can look at our site-wise entropy CAN tell us how many distinct states can be communicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy explains how many protein states can be communicated\n",
    "Trivially, in the \"max possible\" case outlined above, ~51.8 bits of information allows for the communication of $\\begin{equation}4x10^{15}\\end{equation}$ distinct peptide states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recapitulate exactly what we expect to find for num possible states communicated:\n",
      "4.10e+15\n"
     ]
    }
   ],
   "source": [
    "# Remember that this is quite simply just going to be 2^Bits\n",
    "# ie 1 or 2 bits can convey information of 2^1=2 or 2^2=4 states\n",
    "num_states = 2**51.863\n",
    "print('Recapitulate exactly what we expect to find for num possible states communicated:')\n",
    "print(\"{:.2e}\".format(num_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.287712379549449\n",
      "So this \"min\" can actually go lower, because the 10,000 presented are decidedly not equiprobable\n"
     ]
    }
   ],
   "source": [
    "# From the above quoted estimates of single cells at one given time. \n",
    "# 10,000 peptides presented would is this many bits of info:\n",
    "min_entropy = -10000*(1/10000)*math.log(1/10000,2)\n",
    "print(min_entropy)\n",
    "print('So this \"min\" can actually go lower, because the 10,000 presented are decidedly not equiprobable')\n",
    "# Need to go ahead and find that paper where they point out these distributions... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So now, we can take our REAL probability distributions and see how these compare to these upper and lower bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_num_key = aims.get_props()[1]\n",
    "AA_num_key_new = aims.get_props()[2]\n",
    "AA_key = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saved the data from the script on the previous page\n",
    "blood = np.transpose(pandas.read_csv('../Bloodmatrix',sep=',',header=0))\n",
    "skin = np.transpose(pandas.read_csv('../Skinmatrix',sep=',',header=0))\n",
    "skin_A01 = np.transpose(pandas.read_csv('Skin_HLA-A01.csv',sep=',',header=0))\n",
    "blood_A01 = np.transpose(pandas.read_csv('Blood_HLA-A01.csv',sep=',',header=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_T = skin_A01\n",
    "blood_T = blood_A01\n",
    "skin9 = skin_T[skin_T[0].str.len() == 9]\n",
    "skin10 = skin_T[skin_T[0].str.len() == 10]\n",
    "skin11 = skin_T[skin_T[0].str.len() == 11]\n",
    "skin12 = skin_T[skin_T[0].str.len() == 12]\n",
    "\n",
    "blood9 = blood_T[blood_T[0].str.len() == 9]\n",
    "blood10 = blood_T[blood_T[0].str.len() == 10]\n",
    "blood11 = blood_T[blood_T[0].str.len() == 11]\n",
    "blood12 = blood_T[blood_T[0].str.len() == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin9_mat = aims.gen_peptide_matrix(np.array(np.transpose(skin9)),key=AA_num_key,binary = False)\n",
    "blood9_mat = aims.gen_peptide_matrix(np.array(np.transpose(blood9)),key=AA_num_key,binary = False)\n",
    "skin10_mat = aims.gen_peptide_matrix(np.array(np.transpose(skin10)),key=AA_num_key,binary = False)\n",
    "blood10_mat = aims.gen_peptide_matrix(np.array(np.transpose(blood10)),key=AA_num_key,binary = False)\n",
    "skin11_mat = aims.gen_peptide_matrix(np.array(np.transpose(skin11)),key=AA_num_key,binary = False)\n",
    "blood11_mat = aims.gen_peptide_matrix(np.array(np.transpose(blood11)),key=AA_num_key,binary = False)\n",
    "skin12_mat = aims.gen_peptide_matrix(np.array(np.transpose(skin12)),key=AA_num_key,binary = False)\n",
    "blood12_mat = aims.gen_peptide_matrix(np.array(np.transpose(blood12)),key=AA_num_key,binary = False)\n",
    "# Check that this works...\n",
    "#pl.imshow(np.array(seq_MI1),interpolation='nearest', aspect='auto',cmap=cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_b9, count_b9=aims.calculate_shannon(blood9_mat); entropy_s9, count_s9=aims.calculate_shannon(skin9_mat);\n",
    "entropy_b10, count_b10=aims.calculate_shannon(blood10_mat); entropy_s10, count_s10=aims.calculate_shannon(skin10_mat);\n",
    "entropy_b11, count_b11=aims.calculate_shannon(blood11_mat); entropy_s11, count_s11=aims.calculate_shannon(skin11_mat);\n",
    "entropy_b12, count_b12=aims.calculate_shannon(blood12_mat); entropy_s12, count_s12=aims.calculate_shannon(skin12_mat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Length Peptide Entropy (blood, skin)\n",
      "45.244971848075885\n",
      "44.2443449733743\n",
      "11 Lenth Peptide Entropy\n",
      "41.50669569429775\n",
      "40.96030944061604\n",
      "10 Lenth Peptide Entropy\n",
      "37.894650004275235\n",
      "37.45800439977939\n",
      "9 Lenth Peptide Entropy\n",
      "34.35577153364578\n",
      "34.01408740490873\n"
     ]
    }
   ],
   "source": [
    "print('12 Length Peptide Entropy (blood, skin)')\n",
    "print(sum(entropy_b12)); print(sum(entropy_s12))\n",
    "print('11 Lenth Peptide Entropy')\n",
    "print(sum(entropy_b11)); print(sum(entropy_s11))\n",
    "print('10 Lenth Peptide Entropy')\n",
    "print(sum(entropy_b10)); print(sum(entropy_s10))\n",
    "print('9 Lenth Peptide Entropy')\n",
    "print(sum(entropy_b9)); print(sum(entropy_s9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So I don't think that an average is the proper way to account for these differences... BUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood Average Entropy =39.75052227007366\n",
      "Possible Discernible Signals = 9.25e+11\n"
     ]
    }
   ],
   "source": [
    "blood_avg_H = np.average([sum(entropy_b12),sum(entropy_b11),sum(entropy_b10),sum(entropy_b9)])\n",
    "print('Blood Average Entropy = ' + str(blood_avg_H))\n",
    "sci_bloodH = \"{:.2e}\".format(2**blood_avg_H)\n",
    "print('Possible Discernible Signals = '+sci_bloodH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood Encoded Entropy = 38.54627359145295\n",
      "Possible Discernible Signals = 4.01e+11\n"
     ]
    }
   ],
   "source": [
    "ent_encoded = 38.54627359145295\n",
    "print('Blood Encoded Entropy = ' + str(ent_encoded))\n",
    "sci_bloodHenc = \"{:.2e}\".format(2**ent_encoded)\n",
    "print('Possible Discernible Signals = '+sci_bloodHenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Do Everything for JUST HLA-A01:01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Length Peptide Entropy (blood, skin)\n",
      "37.30089358013154\n",
      "38.92447175037396\n",
      "11 Lenth Peptide Entropy\n",
      "34.22284172172966\n",
      "35.255940402172385\n",
      "10 Lenth Peptide Entropy\n",
      "30.86963690621612\n",
      "31.38225261907378\n",
      "9 Lenth Peptide Entropy\n",
      "27.62215318235623\n",
      "27.845821118562505\n"
     ]
    }
   ],
   "source": [
    "print('12 Length Peptide Entropy (blood, skin)')\n",
    "print(sum(entropy_b12)); print(sum(entropy_s12))\n",
    "print('11 Lenth Peptide Entropy')\n",
    "print(sum(entropy_b11)); print(sum(entropy_s11))\n",
    "print('10 Lenth Peptide Entropy')\n",
    "print(sum(entropy_b10)); print(sum(entropy_s10))\n",
    "print('9 Lenth Peptide Entropy')\n",
    "print(sum(entropy_b9)); print(sum(entropy_s9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood Average Entropy = 32.503881347608385\n",
      "Possible Discernible Signals = 6.09e+09\n"
     ]
    }
   ],
   "source": [
    "blood_avg_H = np.average([sum(entropy_b12),sum(entropy_b11),sum(entropy_b10),sum(entropy_b9)])\n",
    "print('Blood Average Entropy = ' + str(blood_avg_H))\n",
    "sci_bloodH = \"{:.2e}\".format(2**blood_avg_H)\n",
    "print('Possible Discernible Signals = '+sci_bloodH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immunopep",
   "language": "python",
   "name": "immunopep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
